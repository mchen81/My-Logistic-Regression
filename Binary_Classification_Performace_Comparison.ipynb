{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47416387",
   "metadata": {},
   "source": [
    "# Binary Classification \n",
    "\n",
    "To compare my implementation of logistic regression with sklearn's in 2 clasiification, I am going to use the [Occupancy Detection Dataset](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+). \n",
    "\n",
    "## Dataset Inspection\n",
    "First of all, let's see what this dataset looks like, and check if there are some invalid value existing.\n",
    "\n",
    "### Samples\n",
    "The dataset contains 1 date, 5 numeric, and 1 classical columns. Also, it's not having any N/A value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8452c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-11 14:48:00</td>\n",
       "      <td>21.7600</td>\n",
       "      <td>31.133333</td>\n",
       "      <td>437.333333</td>\n",
       "      <td>1029.666667</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-11 14:49:00</td>\n",
       "      <td>21.7900</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>437.333333</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-11 14:50:00</td>\n",
       "      <td>21.7675</td>\n",
       "      <td>31.122500</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>1003.750000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-11 14:51:00</td>\n",
       "      <td>21.7675</td>\n",
       "      <td>31.122500</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>1009.500000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-11 14:51:59</td>\n",
       "      <td>21.7900</td>\n",
       "      <td>31.133333</td>\n",
       "      <td>437.333333</td>\n",
       "      <td>1005.666667</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature   Humidity       Light          CO2  \\\n",
       "1  2015-02-11 14:48:00      21.7600  31.133333  437.333333  1029.666667   \n",
       "2  2015-02-11 14:49:00      21.7900  31.000000  437.333333  1000.000000   \n",
       "3  2015-02-11 14:50:00      21.7675  31.122500  434.000000  1003.750000   \n",
       "4  2015-02-11 14:51:00      21.7675  31.122500  439.000000  1009.500000   \n",
       "5  2015-02-11 14:51:59      21.7900  31.133333  437.333333  1005.666667   \n",
       "\n",
       "   HumidityRatio  Occupancy  \n",
       "1       0.005021          1  \n",
       "2       0.005009          1  \n",
       "3       0.005022          1  \n",
       "4       0.005022          1  \n",
       "5       0.005030          1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('occypancy.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c4ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9752 entries, 1 to 9752\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           9752 non-null   object \n",
      " 1   Temperature    9752 non-null   float64\n",
      " 2   Humidity       9752 non-null   float64\n",
      " 3   Light          9752 non-null   float64\n",
      " 4   CO2            9752 non-null   float64\n",
      " 5   HumidityRatio  9752 non-null   float64\n",
      " 6   Occupancy      9752 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 609.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check if null value exists\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf11f6",
   "metadata": {},
   "source": [
    "### Target\n",
    "The Occupancy is the target I'm going to predict. As the cell showing below, it only contains two categories(0 and 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25991661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7703\n",
       "1    2049\n",
       "Name: Occupancy, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the classification of target\n",
    "df['Occupancy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427545e",
   "metadata": {},
   "source": [
    "## Pre-process\n",
    "\n",
    "### Unimportant data - date\n",
    "The date value may not be important to the target. Also, it will be hard for logistic regression to train becuase it's not a numeric data. Though we can trasform it to timestamp as an long value. It does actually not affect the occupancy so I decided to get it dropped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e84bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('date', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fea6b",
   "metadata": {},
   "source": [
    "### Shuffle \n",
    "To make sure the training and testing data are picked in a really random way, it's good to shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8b4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f084d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to features and target\n",
    "features = df.iloc[:, :-1]\n",
    "target = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0301f04",
   "metadata": {},
   "source": [
    "### Standardize and Split\n",
    "I want to standardize the data because the LR in scikit-learn also does it. It also may give us a more accurate prediction than without standardization. \n",
    "\n",
    "This dataset will be splitted for training(80%) and testing(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7916e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Split data to train(80%) and test(20%) \n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "# Because my implementation cannot take array-like features, so here I transform features to dataframe.\n",
    "train_x = pd.DataFrame(train_x)\n",
    "test_x = pd.DataFrame(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c17ca",
   "metadata": {},
   "source": [
    "# Performace Comparison\n",
    "\n",
    "\n",
    "## My Logistic Regression\n",
    "After data is cleaned and standardized, we are okay to process it.   \n",
    "Firstly, I use my implementation of Logistic Regression to fit data and make a prediction.  \n",
    "The following graph is showing that the decreasing of costs among the 10,000 interations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577aaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LogisticRegression import LogisticRegression as MyLR\n",
    "mylr = MyLR()\n",
    "mylr.fit(train_x, train_y)\n",
    "my_hyp = mylr.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747637d",
   "metadata": {},
   "source": [
    "## Sklearn- Logistic Regression\n",
    "\n",
    "Now, I am going to use the logistic regression from sklearn, and compare the accuracy metrix between mine and sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_x, train_y)\n",
    "sk_hyp = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ac02e",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "We will evaluate the explained_variance_score, accuracy_score and confusion_matrix to see the performace between the two versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaadf674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ec9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_evs = explained_variance_score(test_y, my_hyp)\n",
    "my_acc = accuracy_score(test_y, my_hyp)\n",
    "my_cm = confusion_matrix(test_y, my_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ed2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_evs = explained_variance_score(test_y, sk_hyp)\n",
    "sk_acc = accuracy_score(test_y, sk_hyp)\n",
    "sk_cm = confusion_matrix(test_y, sk_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ef2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My Explained Variance Score:\", my_evs)\n",
    "print(\"My Accuracy Score:\", my_acc)\n",
    "print(\"Comfusion Matrix:\")\n",
    "print(my_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sklearn's Explained Variance Score:\", sk_evs)\n",
    "print(\"Sklearn's Accuracy Score:\", sk_acc)\n",
    "print(\"Comfusion Matrix:\")\n",
    "print(sk_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40552353",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As the metrics showing above, the sklearn got a better accuracy and variance. Although my implementation got 95% accuracy, the variance is much lower than sklearn's. Maybe this is because some methods we applied are different. For example, I only used the normal gradient decent to converge the model. On the other hand, the sklearn used [Stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), which is more reliable. ([Source](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/linear_model/_logistic.py))\n",
    "\n",
    "\n",
    "Overall, though we did not make a perfect prediction, the accuracy is high enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
